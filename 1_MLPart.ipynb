{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T07:11:43.566860Z",
     "iopub.status.busy": "2022-12-23T07:11:43.566507Z",
     "iopub.status.idle": "2022-12-23T07:11:43.571905Z",
     "shell.execute_reply": "2022-12-23T07:11:43.570966Z",
     "shell.execute_reply.started": "2022-12-23T07:11:43.566830Z"
    }
   },
   "source": [
    "# STEP5: Sentiment Classification with Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "from scipy import sparse, io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Uploaded Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vaders = pd.read_csv('source/vaders.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import csv file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Test Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On supervised learning we need to train algorithms with datasets train part and testing that trained dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(vaders[\"Text\"], vaders[\"SScoring\"], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Vectorizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train_count = io.mmread('vectorizers/x_train_count.mtx')\n",
    "x_test_count = io.mmread('vectorizers/x_test_count.mtx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### custom n-gram level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tf_idf_ngram = io.mmread(\"vectorizers/x_train_tf_idf_ngram\")\n",
    "x_test_tf_idf_ngram = io.mmread(\"vectorizers/x_test_tf_idf_ngram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word level n_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tf_idf_word = io.mmread(\"vectorizers/x_train_tf_idf_word\")\n",
    "x_test_tf_idf_word = io.mmread(\"vectorizers/x_test_tf_idf_word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### charachter level n_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tf_idf_chars = io.mmread(\"vectorizers/x_train_tf_idf_chars\")\n",
    "x_test_tf_idf_chars = io.mmread(\"vectorizers/x_test_tf_idf_chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_metrix(y_test,y_pred,beta):\n",
    "   CM = confusion_matrix(y_test,y_pred)\n",
    "   TN = CM[0][0]\n",
    "   FN = CM[1][0] \n",
    "   TP = CM[1][1]\n",
    "   FP = CM[0][1]\n",
    "\n",
    "   Recall     = round( TP / (TP+FN),4 ) \n",
    "   Accuracy   = round( (TP+TN) / (TN+FN+TP+FP),4)\n",
    "   Precision  = round( TP / (TP+FP),4 )\n",
    "   F1         = round ( 2 * ((Precision*Recall)/(Precision+Recall)),4)\n",
    "\n",
    "   mat_met = pd.DataFrame({\n",
    "                'Metric':['TP','TN','FP','FN','Recall','Accuracy','Precision','F1'],\n",
    "                'Value':[TP,TN,FP,FN,Recall,Accuracy,Precision,F1]})\n",
    "\n",
    "   return (mat_met)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ML Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- My pc has not enough sources\n",
    "- cpu is quiet slow\n",
    "- these steps running on kaggle\n",
    "- results will give\n",
    "- also kaggle's given ram is not enough so i use mtx files above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model & Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(verbose=2, n_jobs=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--> Checking for physical Tensorflow devices\")\n",
    "for device in tf.config.list_physical_devices():\n",
    "    print(\": {}\".format(device.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    rf_model_count = rf.fit(x_train_count, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process takes 2 hour 27 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy\n",
    "accuracy_score(y_train,rf_model_count.predict(x_train_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "y_pred_rf_count = rf_model_count.predict(x_test_count)\n",
    "accuracy_score(y_test, y_pred_rf_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.4\n",
    "mat_met = matrix_metrix(y_test,y_pred_rf_count,beta)\n",
    "print (mat_met)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### n-gram level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_ngram = joblib.load(\"models/rf_model_ngram.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    rf_model_ngram = rf.fit(x_train_tf_idf_ngram, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train,rf_model_ngram.predict(x_train_tf_idf_ngram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_ngram = rf_model_ngram.predict(x_test_tf_idf_ngram)\n",
    "accuracy_score(y_test, y_pred_rf_ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process takes 7 hour 10 minutes. Really slow because didn't remain n_jobs parameter. n_jobs run multi process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.4\n",
    "mat_met = matrix_metrix(y_test,y_pred_rf_ngram,beta)\n",
    "print (mat_met)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    rf_model_word = rf.fit(x_train_tf_idf_word, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train,rf_model_word.predict(x_train_tf_idf_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_word = rf_model_word.predict(x_test_tf_idf_word)\n",
    "accuracy_score(y_test, y_pred_rf_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.4\n",
    "mat_met = matrix_metrix(y_test,y_pred_rf_word,beta)\n",
    "print (mat_met)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    rf_model_chars = rf.fit(x_train_tf_idf_chars, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train,rf_model_chars.predict(x_train_tf_idf_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_chars = rf_model_chars.predict(x_test_tf_idf_chars)\n",
    "accuracy_score(y_test, y_pred_rf_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.4\n",
    "mat_met = matrix_metrix(y_test,y_pred_rf_chars,beta)\n",
    "print (mat_met)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These steps implements rf model tuning. Hard to run so I won't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\"n_estimators\": [500,1000, 2000],\n",
    "             \"max_depth\": [5,8,10],\n",
    "             \"max_features\": [2,5,8],\n",
    "             \"min_samples_split\": [2,5,8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    rf_cv = GridSearchCV(rf_model_word, rf_params, cv=10, n_jobs=-1, verbose=2)\n",
    "    rf_cv.fit(x_train_tf_idf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Score: \"+ str(rf_cv.best_score_))\n",
    "print(\"Best Parameters: \"+ str(rf_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    rf_tuned = RandomForestClassifier(max_depth=8,\n",
    "                                     max_features=8,\n",
    "                                     min_samples_split=5,\n",
    "                                     n_estimators=1000)\n",
    "\n",
    "    rf_tuned.fit(x_train_tf_idf_word, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_tuned.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model & Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    xgb_model_count = xgb.fit(x_train_count, y_train, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost training almost 22 times faster than Random Forests!!! It' s nearly takes 7 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train,  xgb_model_count.predict(x_train_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb_count = xgb_model_count.predict(x_test_count)\n",
    "accuracy_score(y_test, y_pred_xgb_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.4\n",
    "mat_met = matrix_metrix(y_test,y_pred_xgb_count,beta)\n",
    "print (mat_met)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ngram level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    xgb_model_ngram = xgb.fit(x_train_tf_idf_ngram, y_train, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train,  xgb_model_ngram.predict(x_train_tf_idf_ngram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb_ngram = xgb_model_ngram.predict(x_test_tf_idf_ngram)\n",
    "accuracy_score(y_test, y_pred_xgb_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.4\n",
    "mat_met = matrix_metrix(y_test,y_pred_xgb_ngram,beta)\n",
    "print (mat_met)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    xgb_model_word = xgb.fit(x_train_tf_idf_word, y_train, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train,  xgb_model_word.predict(x_train_tf_idf_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb_word = xgb_model_word.predict(x_test_tf_idf_word)\n",
    "accuracy_score(y_test, y_pred_xgb_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.4\n",
    "mat_met = matrix_metrix(y_test,y_pred_xgb_word,beta)\n",
    "print (mat_met)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    xgb_model_chars = xgb.fit(x_train_tf_idf_chars, y_train, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train,  xgb_model_chars.predict(x_train_tf_idf_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb_chars = xgb_model_chars.predict(x_test_tf_idf_chars)\n",
    "accuracy_score(y_test, y_pred_xgb_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.4\n",
    "mat_met = matrix_metrix(y_test,y_pred_xgb_chars,beta)\n",
    "print (mat_met)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These steps takes too much time and effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\"learning_rate\": [0.01, 0.001],\n",
    "              \"n_estimators\": [500,1000,2000],\n",
    "              \"max_depth\": [5,6,7],\n",
    "              \"subsample\": [0.6, 0.7, 0.8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    xgb_cv = GridSearchCV(xgb_model_word, xgb_params, cv=10, verbose=2)\n",
    "    xgb_cv.fit(x_train_tf_idf_word, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Score: \"+ str(xgb_cv.best_score_))\n",
    "print(\"Best Parameters: \"+ str(xgb_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    xgb = XGBClassifier(learning_rate=0.001,\n",
    "                        max_depth=6,\n",
    "                        min_samples_split=2,\n",
    "                        n_estimators=1000,\n",
    "                        subsample=0.6)\n",
    "\n",
    "    xgb_tuned = xgb.fit(x_train_tf_idf_word, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_tuned.predict(x_test_tf_idf_word)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model & Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = CatBoostClassifier(verbose=2, iterations= 500, thread_count=-1, depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    cb_count = cb.fit(x_train_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train, cb_count.predict(x_train_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cb_count = cb_count.predict(x_test_count)\n",
    "accuracy_score(y_test, y_pred_cb_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.4\n",
    "mat_met = matrix_metrix(y_test,y_pred_cb_count,beta)\n",
    "print (mat_met)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ngram level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    cb_ngram = cb.fit(x_train_tf_idf_ngram, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train, cb_ngram.predict(x_train_tf_idf_ngram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cb_ngram = cb_ngram.predict(x_test_tf_idf_ngram)\n",
    "accuracy_score(y_test, y_pred_cb_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.4\n",
    "mat_met = matrix_metrix(y_test,y_pred_cb_ngram,beta)\n",
    "print (mat_met)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    cb_word = cb.fit(x_train_tf_idf_word, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train, cb_word.predict(x_train_tf_idf_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cb_word = cb_word.predict(x_test_tf_idf_word)\n",
    "accuracy_score(y_test, y_pred_cb_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.4\n",
    "mat_met = matrix_metrix(y_test,y_pred_cb_word,beta)\n",
    "print (mat_met)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    cb_chars = cb.fit(x_train_tf_idf_chars, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train, cb_chars.predict(x_train_tf_idf_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cb_chars = cb_chars.predict(x_test_tf_idf_chars)\n",
    "accuracy_score(y_test, y_pred_cb_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.4\n",
    "mat_met = matrix_metrix(y_test,y_pred_cb_chars,beta)\n",
    "print (mat_met)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Fitted Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save rf count vectors model\n",
    "joblib.dump(rf_model_count, \"models/rf_model_count.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(rf_model_ngram,\"models/rf_model_ngram.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(rf_model_word,\"models/rf_model_word.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(rf_model_chars,\"models/rf_model_chars.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(xgb_model_count,\"models/xgb_model_count.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(xgb_model_ngram,\"models/xgb_model_ngram.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(xgb_model_word,\"models/xgb_model_word.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(xgb_model_chars,\"models/xgb_model_chars.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(cb_count,\"models/cb_count.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(cb_ngram,\"models/cb_ngram.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(cb_word,\"models/cb_word.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(cb_chars,\"models/cb_chars.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if you wanna compress\n",
    "#joblib.dump(rf, \"RF_compressed.joblib\", compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load rf count vectors model\n",
    "#loaded_rf = joblib.load(\"./rf_model_count.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## another method\n",
    "#import cPickle\n",
    "#rf = RandomForestRegresor()\n",
    "#rf.fit(X, y)\n",
    "\n",
    "#with open('path/to/file', 'wb') as f:\n",
    "#    cPickle.dump(rf, f)\n",
    "\n",
    "## in your prediction file                                                                                                                                                                                                           \n",
    "#with open('path/to/file', 'rb') as f:\n",
    "#    rf = cPickle.load(f)\n",
    "\n",
    "#preds = rf.predict(new_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
